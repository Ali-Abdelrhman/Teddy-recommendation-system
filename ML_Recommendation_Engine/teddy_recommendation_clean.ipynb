{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a29cf06",
   "metadata": {},
   "source": [
    "# 1) Import Libraries and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87720e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All libraries imported successfully!\n",
      "ðŸŽ¯ Ready to build the Teddy Recommendation System!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import time\n",
    "\n",
    "# Machine Learning libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")\n",
    "print(\"ðŸŽ¯ Ready to build the Teddy Recommendation System!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daa75701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Loading data...\n",
      "âœ… Loaded 14,339 products and 787,416 user events\n",
      "ðŸ”„ Preprocessing products with enhanced fields...\n",
      "âœ… Processed 14,339 products with enhanced fields\n",
      "ðŸ“Š Categories: 46, Brands: 981\n",
      "ðŸŽ¯ New Fields: Age Groups: 27, Colors: 13\n",
      "ðŸ“¦ Availability: {'IN_STOCK': 14339}\n",
      "ðŸ”„ Preprocessing user events...\n",
      "âœ… Loaded 14,339 products and 787,416 user events\n",
      "ðŸ”„ Preprocessing products with enhanced fields...\n",
      "âœ… Processed 14,339 products with enhanced fields\n",
      "ðŸ“Š Categories: 46, Brands: 981\n",
      "ðŸŽ¯ New Fields: Age Groups: 27, Colors: 13\n",
      "ðŸ“¦ Availability: {'IN_STOCK': 14339}\n",
      "ðŸ”„ Preprocessing user events...\n",
      "âœ… Processed 787,416 events into 696,888 user-product interactions\n",
      "ðŸ‘¥ Users: 466,475\n",
      "âœ… Processed 787,416 events into 696,888 user-product interactions\n",
      "ðŸ‘¥ Users: 466,475\n",
      "ðŸ“¦ Products: 14,339\n",
      "ðŸ“¦ Products: 14,339\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "def load_data():\n",
    "    \"\"\"Load products and user events data\"\"\"\n",
    "    print(\"ðŸ”„ Loading data...\")\n",
    "    \n",
    "    # Load products\n",
    "    with open('final_catalog_clean_urls.ndjson', 'r', encoding='utf-8') as f:\n",
    "        raw_products = [json.loads(line) for line in f]\n",
    "    \n",
    "    # Load user events\n",
    "    with open('catalog_user_events_gcp_final.ndjson', 'r', encoding='utf-8') as f:\n",
    "        raw_events = [json.loads(line) for line in f]\n",
    "    \n",
    "    print(f\"âœ… Loaded {len(raw_products):,} products and {len(raw_events):,} user events\")\n",
    "    return raw_products, raw_events\n",
    "\n",
    "def preprocess_products(raw_products):\n",
    "    \"\"\"Clean and preprocess product data with enhanced field extraction\"\"\"\n",
    "    print(\"ðŸ”„ Preprocessing products with enhanced fields...\")\n",
    "    \n",
    "    processed_products = []\n",
    "    for product in raw_products:\n",
    "        # Extract and clean basic fields\n",
    "        product_info = {\n",
    "            'product_id': str(product.get('id', '')),\n",
    "            'title': str(product.get('title', '')),\n",
    "            'description': str(product.get('description', '')),\n",
    "            'category_main': str(product.get('categories', ['Unknown'])[0] if product.get('categories') else 'Unknown'),\n",
    "            'brand_main': str(product.get('brands', ['Unknown'])[0] if product.get('brands') else 'Unknown'),\n",
    "            'price': float(product.get('priceInfo', {}).get('price', 0)),\n",
    "            \n",
    "            # Enhanced fields for better recommendations\n",
    "            'age_group': str(product.get('attributes', {}).get('age_group', {}).get('text', [''])[0] if product.get('attributes', {}).get('age_group', {}).get('text') else ''),\n",
    "            'color': str(product.get('attributes', {}).get('color', {}).get('text', [''])[0] if product.get('attributes', {}).get('color', {}).get('text') else ''),\n",
    "            'features': ' '.join(product.get('attributes', {}).get('features', {}).get('text', [])) if product.get('attributes', {}).get('features', {}).get('text') else '',\n",
    "            'tags': ' '.join(product.get('tags', [])) if product.get('tags') else '',\n",
    "            'availability': str(product.get('availability', 'UNKNOWN')),\n",
    "            'original_price': float(product.get('priceInfo', {}).get('originalPrice', 0)),\n",
    "            \n",
    "            # Legacy fields\n",
    "            'gender': str(product.get('attributes', {}).get('gender', {}).get('text', [''])[0] if product.get('attributes', {}).get('gender', {}).get('text') else '')\n",
    "        }\n",
    "        \n",
    "        # Calculate discount percentage for deal-based recommendations\n",
    "        if product_info['original_price'] > 0 and product_info['price'] > 0:\n",
    "            product_info['discount_percent'] = ((product_info['original_price'] - product_info['price']) / product_info['original_price']) * 100\n",
    "        else:\n",
    "            product_info['discount_percent'] = 0.0\n",
    "        \n",
    "        # Create enhanced combined text features with new fields\n",
    "        product_info['combined_features'] = f\"{product_info['category_main']} {product_info['brand_main']} {product_info['age_group']} {product_info['color']} {product_info['features']} {product_info['tags']} {product_info['gender']}\"\n",
    "        product_info['content_text'] = f\"{product_info['title']} {product_info['description']} {product_info['combined_features']}\"\n",
    "        \n",
    "        processed_products.append(product_info)\n",
    "    \n",
    "    products_df = pd.DataFrame(processed_products)\n",
    "    print(f\"âœ… Processed {len(products_df):,} products with enhanced fields\")\n",
    "    print(f\"ðŸ“Š Categories: {products_df['category_main'].nunique()}, Brands: {products_df['brand_main'].nunique()}\")\n",
    "    print(f\"ðŸŽ¯ New Fields: Age Groups: {products_df['age_group'].nunique()}, Colors: {products_df['color'].nunique()}\")\n",
    "    print(f\"ðŸ“¦ Availability: {products_df['availability'].value_counts().to_dict()}\")\n",
    "    \n",
    "    return products_df\n",
    "\n",
    "def preprocess_events(raw_events):\n",
    "    \"\"\"Clean and preprocess user events\"\"\"\n",
    "    print(\"ðŸ”„ Preprocessing user events...\")\n",
    "    \n",
    "    events_data = []\n",
    "    for event in raw_events:\n",
    "        # Extract visitor/user ID\n",
    "        visitor_id = str(event.get('visitorId', ''))\n",
    "        \n",
    "        # Extract product details (can be multiple products per event)\n",
    "        product_details = event.get('productDetails', [])\n",
    "        if not product_details:\n",
    "            continue\n",
    "            \n",
    "        # Extract event type and map it\n",
    "        event_type = str(event.get('eventType', ''))\n",
    "        event_type_mapped = {\n",
    "            'detail-page-view': 'view',\n",
    "            'add-to-cart': 'add_to_cart', \n",
    "            'purchase-complete': 'purchase'\n",
    "        }.get(event_type, 'view')\n",
    "        \n",
    "        # Create event for each product in the event\n",
    "        for product_detail in product_details:\n",
    "            product_info = product_detail.get('product', {})\n",
    "            product_id = str(product_info.get('id', ''))\n",
    "            \n",
    "            if product_id and visitor_id:\n",
    "                event_info = {\n",
    "                    'user_id': visitor_id,\n",
    "                    'product_id': product_id,\n",
    "                    'event_type': event_type_mapped,\n",
    "                    'timestamp': event.get('eventTime', 0)\n",
    "                }\n",
    "                events_data.append(event_info)\n",
    "    \n",
    "    events_df = pd.DataFrame(events_data)\n",
    "    \n",
    "    # Create interaction matrix with weights\n",
    "    # Weight: view=1, cart=2, purchase=3\n",
    "    weight_map = {'view': 1, 'add_to_cart': 2, 'purchase': 3}\n",
    "    events_df['weight'] = events_df['event_type'].map(weight_map).fillna(1)\n",
    "    \n",
    "    # Aggregate interactions\n",
    "    interaction_matrix = events_df.groupby(['user_id', 'product_id'])['weight'].sum().reset_index()\n",
    "    \n",
    "    print(f\"âœ… Processed {len(events_df):,} events into {len(interaction_matrix):,} user-product interactions\")\n",
    "    print(f\"ðŸ‘¥ Users: {interaction_matrix['user_id'].nunique():,}\")\n",
    "    print(f\"ðŸ“¦ Products: {interaction_matrix['product_id'].nunique():,}\")\n",
    "    \n",
    "    return events_df, interaction_matrix\n",
    "\n",
    "# Load and preprocess all data\n",
    "raw_products, raw_events = load_data()\n",
    "products_df = preprocess_products(raw_products)\n",
    "events_df, interaction_matrix = preprocess_events(raw_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62a29808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Creating feature matrices...\n",
      "âœ… TF-IDF matrix created: (14339, 5000)\n",
      "âœ… TF-IDF matrix created: (14339, 5000)\n",
      "âœ… Sparse matrix created: (466475, 14339)\n",
      "ðŸ“Š Matrix density: 0.0104%\n",
      "âœ… Sparse matrix created: (466475, 14339)\n",
      "ðŸ“Š Matrix density: 0.0104%\n"
     ]
    }
   ],
   "source": [
    "# Create feature matrices and mappings\n",
    "def create_feature_matrices(products_df, interaction_matrix):\n",
    "    \"\"\"Create TF-IDF matrix and user-product mappings\"\"\"\n",
    "    print(\"ðŸ”„ Creating feature matrices...\")\n",
    "    \n",
    "    # Create TF-IDF matrix for content-based filtering\n",
    "    tfidf_vectorizer = TfidfVectorizer(\n",
    "        max_features=5000,\n",
    "        stop_words='english',\n",
    "        ngram_range=(1, 2),\n",
    "        min_df=2,\n",
    "        max_df=0.8\n",
    "    )\n",
    "    \n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(products_df['content_text'])\n",
    "    print(f\"âœ… TF-IDF matrix created: {tfidf_matrix.shape}\")\n",
    "    \n",
    "    # Create user and product mappings for collaborative filtering\n",
    "    users = interaction_matrix['user_id'].unique()\n",
    "    products = interaction_matrix['product_id'].unique()\n",
    "    \n",
    "    user_to_idx = {user: idx for idx, user in enumerate(users)}\n",
    "    product_to_idx = {product: idx for idx, product in enumerate(products)}\n",
    "    idx_to_user = {idx: user for user, idx in user_to_idx.items()}\n",
    "    idx_to_product = {idx: product for product, idx in product_to_idx.items()}\n",
    "    \n",
    "    # Create sparse matrix for collaborative filtering\n",
    "    rows = [user_to_idx[user] for user in interaction_matrix['user_id']]\n",
    "    cols = [product_to_idx[product] for product in interaction_matrix['product_id']]\n",
    "    data = interaction_matrix['weight'].values\n",
    "    \n",
    "    sparse_matrix = csr_matrix((data, (rows, cols)), shape=(len(users), len(products)))\n",
    "    \n",
    "    print(f\"âœ… Sparse matrix created: {sparse_matrix.shape}\")\n",
    "    print(f\"ðŸ“Š Matrix density: {sparse_matrix.nnz / (sparse_matrix.shape[0] * sparse_matrix.shape[1]) * 100:.4f}%\")\n",
    "    \n",
    "    return tfidf_matrix, tfidf_vectorizer, sparse_matrix, user_to_idx, product_to_idx, idx_to_user, idx_to_product\n",
    "\n",
    "# Create all feature matrices\n",
    "tfidf_matrix, tfidf_vectorizer, sparse_matrix, user_to_idx, product_to_idx, idx_to_user, idx_to_product = create_feature_matrices(products_df, interaction_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a31b3a",
   "metadata": {},
   "source": [
    "# 2) Model Training with Enhanced Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b890f5",
   "metadata": {},
   "source": [
    "## i) Content-Based Recommender with Enhanced Brand Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0509f009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Training Enhanced Content-Based Recommender...\n",
      "âœ… Enhanced Content-Based initialized\n",
      "ðŸ“Š 14339 products, 981 brands, 46 categories\n",
      "âœ… Enhanced Content-Based Recommender ready!\n",
      "âœ… Enhanced Content-Based initialized\n",
      "ðŸ“Š 14339 products, 981 brands, 46 categories\n",
      "âœ… Enhanced Content-Based Recommender ready!\n"
     ]
    }
   ],
   "source": [
    "class ContentBasedRecommender:\n",
    "    \"\"\"Ultra-Enhanced Content-Based Recommender for Maximum Brand & Category Coverage\"\"\"\n",
    "    \n",
    "    def __init__(self, products_df, tfidf_matrix, interaction_matrix):\n",
    "        self.products_df = products_df.reset_index(drop=True)\n",
    "        self.tfidf_matrix = tfidf_matrix\n",
    "        self.interaction_matrix = interaction_matrix\n",
    "        \n",
    "        # Create mappings\n",
    "        self.product_id_to_idx = {pid: idx for idx, pid in enumerate(products_df['product_id'])}\n",
    "        self.idx_to_product_id = {idx: pid for pid, idx in self.product_id_to_idx.items()}\n",
    "        \n",
    "        # Brand and category analytics\n",
    "        self.brand_counts = Counter(products_df['brand_main'])\n",
    "        self.category_counts = Counter(products_df['category_main'])\n",
    "        self.total_brands = len(self.brand_counts)\n",
    "        self.total_categories = len(self.category_counts)\n",
    "        \n",
    "        # Create brand-product and category-product mappings for diversity\n",
    "        self.brand_products = {}\n",
    "        self.category_products = {}\n",
    "        for idx, row in products_df.iterrows():\n",
    "            brand, category, pid = row['brand_main'], row['category_main'], row['product_id']\n",
    "            self.brand_products.setdefault(brand, []).append((pid, idx))\n",
    "            self.category_products.setdefault(category, []).append((pid, idx))\n",
    "        \n",
    "        print(f\"âœ… Enhanced Content-Based initialized\")\n",
    "        print(f\"ðŸ“Š {len(products_df)} products, {self.total_brands} brands, {self.total_categories} categories\")\n",
    "    \n",
    "    def get_user_recommendations(self, user_id, n_recommendations=10):\n",
    "        \"\"\"Enhanced recommendations with availability, age-appropriate, and discount filtering\"\"\"\n",
    "        user_interactions = self.interaction_matrix[self.interaction_matrix['user_id'] == user_id]\n",
    "        if user_interactions.empty:\n",
    "            return self._cold_start_diverse_recommendations(n_recommendations)\n",
    "        \n",
    "        # Build user profile from interactions (key technique from old notebook)\n",
    "        user_products = set(user_interactions['product_id'])\n",
    "        user_brands = set()\n",
    "        user_categories = set()\n",
    "        user_age_groups = set()\n",
    "        user_colors = set()\n",
    "        \n",
    "        for pid in user_products:\n",
    "            if pid in self.product_id_to_idx:\n",
    "                idx = self.product_id_to_idx[pid]\n",
    "                product = self.products_df.iloc[idx]\n",
    "                user_brands.add(product['brand_main'])\n",
    "                user_categories.add(product['category_main'])\n",
    "                if product['age_group']:\n",
    "                    user_age_groups.add(product['age_group'])\n",
    "                if product['color']:\n",
    "                    user_colors.add(product['color'])\n",
    "        \n",
    "        # Create enhanced user profile vector\n",
    "        user_categories_text = ' '.join(user_categories) if user_categories else ''\n",
    "        user_brands_text = ' '.join(user_brands) if user_brands else ''\n",
    "        user_ages_text = ' '.join(user_age_groups) if user_age_groups else ''\n",
    "        user_colors_text = ' '.join(user_colors) if user_colors else ''\n",
    "        user_profile_text = f\"{user_categories_text} {user_brands_text} {user_ages_text} {user_colors_text}\".strip()\n",
    "        \n",
    "        if not user_profile_text:\n",
    "            return self._cold_start_diverse_recommendations(n_recommendations)\n",
    "        \n",
    "        # Compute similarities efficiently using TF-IDF (proven approach)\n",
    "        from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "        from sklearn.metrics.pairwise import cosine_similarity\n",
    "        \n",
    "        # Create user vector\n",
    "        temp_vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "        combined_texts = [user_profile_text] + self.products_df['content_text'].tolist()\n",
    "        temp_matrix = temp_vectorizer.fit_transform(combined_texts)\n",
    "        \n",
    "        user_vector = temp_matrix[0:1]  # First row is user profile\n",
    "        product_vectors = temp_matrix[1:]  # Rest are products\n",
    "        \n",
    "        # Calculate similarities\n",
    "        similarities = cosine_similarity(user_vector, product_vectors).flatten()\n",
    "        \n",
    "        # Apply enhanced filtering and scoring logic\n",
    "        recommendations_list = []\n",
    "        brand_count = {}\n",
    "        \n",
    "        # Sort products by similarity\n",
    "        product_indices = np.argsort(similarities)[::-1]\n",
    "        \n",
    "        for idx in product_indices:\n",
    "            if len(recommendations_list) >= n_recommendations * 3:  # Search pool\n",
    "                break\n",
    "                \n",
    "            product = self.products_df.iloc[idx]\n",
    "            product_id = product['product_id']\n",
    "            \n",
    "            # Skip already interacted products\n",
    "            if product_id in user_products:\n",
    "                continue\n",
    "            \n",
    "            # AVAILABILITY FILTERING - Only recommend IN_STOCK products\n",
    "            if product['availability'] != 'IN_STOCK':\n",
    "                continue\n",
    "            \n",
    "            # AGE-APPROPRIATE FILTERING - Match user's age groups if available\n",
    "            if user_age_groups and product['age_group']:\n",
    "                age_compatible = False\n",
    "                for user_age in user_age_groups:\n",
    "                    if user_age in product['age_group'] or product['age_group'] in user_age:\n",
    "                        age_compatible = True\n",
    "                        break\n",
    "                if not age_compatible:\n",
    "                    continue\n",
    "            \n",
    "            brand = product['brand_main']\n",
    "            similarity_score = similarities[idx]\n",
    "            \n",
    "            # Enhanced brand diversity scoring (key improvement from old notebook)\n",
    "            brand_boost_factor = 1.5  # Brand boost for diversity\n",
    "            if brand in user_brands:\n",
    "                # Boost familiar brands\n",
    "                final_score = similarity_score * brand_boost_factor\n",
    "            else:\n",
    "                # Boost new brands for diversity\n",
    "                final_score = similarity_score * (brand_boost_factor * 1.2)\n",
    "            \n",
    "            # DISCOUNT-BASED SCORING - Boost products with good discounts\n",
    "            if product['discount_percent'] > 0:\n",
    "                discount_boost = min(1 + (product['discount_percent'] / 100), 2.0)  # Max 2x boost\n",
    "                final_score *= discount_boost\n",
    "            \n",
    "            # COLOR PREFERENCE SCORING - Boost matching colors\n",
    "            if user_colors and product['color'] and product['color'] in user_colors:\n",
    "                final_score *= 1.3\n",
    "            \n",
    "            # Apply brand count penalty to ensure diversity\n",
    "            if brand in brand_count:\n",
    "                if brand_count[brand] >= 2:  # Limit per brand\n",
    "                    continue\n",
    "                final_score *= 0.8  # Slight penalty for repeated brands\n",
    "            else:\n",
    "                brand_count[brand] = 0\n",
    "            \n",
    "            brand_count[brand] += 1\n",
    "            \n",
    "            recommendations_list.append({\n",
    "                'product_id': product_id,\n",
    "                'title': product['title'],\n",
    "                'brand': brand,\n",
    "                'category': product['category_main'],\n",
    "                'price': product['price'],\n",
    "                'age_group': product['age_group'],\n",
    "                'color': product['color'],\n",
    "                'discount_percent': product['discount_percent'],\n",
    "                'availability': product['availability'],\n",
    "                'recommendation_score': final_score,\n",
    "                'source': 'enhanced_similarity'\n",
    "            })\n",
    "        \n",
    "        # Sort by final score and return top recommendations\n",
    "        recommendations_list.sort(key=lambda x: x['recommendation_score'], reverse=True)\n",
    "        return recommendations_list[:n_recommendations]\n",
    "    \n",
    "    def _cold_start_diverse_recommendations(self, n_recommendations):\n",
    "        \"\"\"Enhanced cold start with availability and discount filtering\"\"\"\n",
    "        # Filter for IN_STOCK products only\n",
    "        available_products = self.products_df[self.products_df['availability'] == 'IN_STOCK']\n",
    "        \n",
    "        # For cold start, recommend popular products with brand diversity\n",
    "        popular_products = self.interaction_matrix.groupby('product_id')['weight'].sum().reset_index()\n",
    "        popular_products = popular_products.sort_values('weight', ascending=False)\n",
    "        \n",
    "        recommendations = []\n",
    "        brand_count = {}\n",
    "        brand_boost_factor = 1.5\n",
    "        \n",
    "        for _, product_interaction in popular_products.iterrows():\n",
    "            if len(recommendations) >= n_recommendations * 2:  # Search pool\n",
    "                break\n",
    "                \n",
    "            product_id = product_interaction['product_id']\n",
    "            if product_id not in self.product_id_to_idx:\n",
    "                continue\n",
    "                \n",
    "            idx = self.product_id_to_idx[product_id]\n",
    "            product = self.products_df.iloc[idx]\n",
    "            \n",
    "            # AVAILABILITY FILTERING for cold start\n",
    "            if product['availability'] != 'IN_STOCK':\n",
    "                continue\n",
    "                \n",
    "            brand = product['brand_main']\n",
    "            \n",
    "            # Apply brand diversity with boost (key technique from old notebook)\n",
    "            base_score = product_interaction['weight']\n",
    "            \n",
    "            # DISCOUNT-BASED SCORING for cold start\n",
    "            if product['discount_percent'] > 0:\n",
    "                discount_boost = min(1 + (product['discount_percent'] / 100), 2.0)\n",
    "                base_score *= discount_boost\n",
    "            \n",
    "            # Brand diversity scoring\n",
    "            if brand in brand_count:\n",
    "                if brand_count[brand] >= 2:  # Limit brands\n",
    "                    continue\n",
    "                final_score = base_score * 0.8  # Penalty for repeated brands\n",
    "            else:\n",
    "                # Boost for new brands with rarity consideration\n",
    "                frequency = self.brand_counts[brand] / len(self.products_df)\n",
    "                rarity_multiplier = min(20.0 / frequency, 100.0)\n",
    "                final_score = base_score * brand_boost_factor * rarity_multiplier\n",
    "                brand_count[brand] = 0\n",
    "            \n",
    "            brand_count[brand] += 1\n",
    "            \n",
    "            recommendations.append({\n",
    "                'product_id': product_id,\n",
    "                'title': product['title'],\n",
    "                'brand': brand,\n",
    "                'category': product['category_main'],\n",
    "                'price': product['price'],\n",
    "                'age_group': product['age_group'],\n",
    "                'color': product['color'],\n",
    "                'discount_percent': product['discount_percent'],\n",
    "                'availability': product['availability'],\n",
    "                'recommendation_score': final_score,\n",
    "                'source': 'enhanced_cold_start'\n",
    "            })\n",
    "        \n",
    "        # Sort by final score and return top recommendations\n",
    "        recommendations.sort(key=lambda x: x['recommendation_score'], reverse=True)\n",
    "        return recommendations[:n_recommendations]\n",
    "\n",
    "# Initialize Enhanced Content-Based Recommender\n",
    "print(\"ðŸ”„ Training Enhanced Content-Based Recommender...\")\n",
    "content_recommender = ContentBasedRecommender(products_df, tfidf_matrix, interaction_matrix)\n",
    "print(\"âœ… Enhanced Content-Based Recommender ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24105f3",
   "metadata": {},
   "source": [
    "## ii) Collaborative Filtering with Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48255fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Enhanced CF initialized - 466,475 users, 14,339 products\n",
      "âœ… Model trained - RMSE: 1.7233\n",
      "âœ… Enhanced Collaborative Filtering ready!\n",
      "âœ… Model trained - RMSE: 1.7233\n",
      "âœ… Enhanced Collaborative Filtering ready!\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "import numpy as np\n",
    "\n",
    "class CollaborativeFilteringRecommender:\n",
    "    \"\"\"Collaborative Filtering with Enhanced Brand Diversity and Filtering\"\"\"\n",
    "    \n",
    "    def __init__(self, interaction_matrix, products_df, min_interactions=1):\n",
    "        self.interaction_matrix = interaction_matrix\n",
    "        self.products_df = products_df\n",
    "        \n",
    "        # Filter data\n",
    "        user_counts = interaction_matrix['user_id'].value_counts()\n",
    "        product_counts = interaction_matrix['product_id'].value_counts()\n",
    "        active_users = user_counts[user_counts >= min_interactions].index\n",
    "        available_products = product_counts[product_counts >= 1].index\n",
    "        \n",
    "        self.filtered_interaction_matrix = interaction_matrix[\n",
    "            (interaction_matrix['user_id'].isin(active_users)) & \n",
    "            (interaction_matrix['product_id'].isin(available_products))\n",
    "        ]\n",
    "        \n",
    "        self.unique_users = sorted(self.filtered_interaction_matrix['user_id'].unique())\n",
    "        self.unique_products = sorted(self.filtered_interaction_matrix['product_id'].unique())\n",
    "        \n",
    "        # Create mappings and metadata\n",
    "        self.user_to_idx = {user: idx for idx, user in enumerate(self.unique_users)}\n",
    "        self.product_to_idx = {product: idx for idx, product in enumerate(self.unique_products)}\n",
    "        self.idx_to_product = {idx: product for product, idx in self.product_to_idx.items()}\n",
    "        self.brand_counts = Counter(products_df['brand_main'])\n",
    "        self.product_metadata = {\n",
    "            row['product_id']: {\n",
    "                'brand': row['brand_main'], 'category': row['category_main'],\n",
    "                'title': row['title'], 'price': row['price'],\n",
    "                'age_group': row['age_group'], 'color': row['color'],\n",
    "                'discount_percent': row['discount_percent'], 'availability': row['availability']\n",
    "            }\n",
    "            for _, row in products_df.iterrows()\n",
    "        }\n",
    "        \n",
    "        print(f\"âœ… Enhanced CF initialized - {len(self.unique_users):,} users, {len(self.unique_products):,} products\")\n",
    "    \n",
    "    def _create_sparse_matrix(self):\n",
    "        \"\"\"Create sparse user-product interaction matrix\"\"\"\n",
    "        rows, cols, data = [], [], []\n",
    "        for _, row in self.filtered_interaction_matrix.iterrows():\n",
    "            if row['user_id'] in self.user_to_idx and row['product_id'] in self.product_to_idx:\n",
    "                rows.append(self.user_to_idx[row['user_id']])\n",
    "                cols.append(self.product_to_idx[row['product_id']])\n",
    "                data.append(row['weight'])\n",
    "        \n",
    "        return csr_matrix((data, (rows, cols)), shape=(len(self.unique_users), len(self.unique_products)))\n",
    "    \n",
    "    def train_model(self, n_factors=60):\n",
    "        \"\"\"Train SVD model with improved accuracy\"\"\"\n",
    "        sparse_matrix = self._create_sparse_matrix()\n",
    "        \n",
    "        try:\n",
    "            U, sigma, Vt = svds(sparse_matrix.astype(np.float64), k=n_factors, solver='arpack')\n",
    "            \n",
    "            # Store components with regularization\n",
    "            self.U = U\n",
    "            self.sigma = sigma + 0.01  # Light regularization\n",
    "            self.Vt = Vt\n",
    "            \n",
    "            # Calculate RMSE on sample\n",
    "            sample_size = min(10000, sparse_matrix.nnz)\n",
    "            test_indices = np.random.choice(sparse_matrix.nnz, sample_size, replace=False)\n",
    "            rows, cols = sparse_matrix.nonzero()\n",
    "            \n",
    "            actual = sparse_matrix.data[test_indices]\n",
    "            predicted = [np.dot(U[rows[i], :], self.sigma * Vt[:, cols[i]]) for i in test_indices]\n",
    "            \n",
    "            rmse = np.sqrt(mean_squared_error(actual, predicted))\n",
    "            print(f\"âœ… Model trained - RMSE: {rmse:.4f}\")\n",
    "            \n",
    "            self._create_brand_aware_popularity()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ SVD failed: {e}\")\n",
    "            self._create_brand_aware_popularity()\n",
    "    \n",
    "    def _create_brand_aware_popularity(self):\n",
    "        \"\"\"Create enhanced brand-diversified popularity fallback\"\"\"\n",
    "        popularity = self.filtered_interaction_matrix.groupby('product_id')['weight'].sum()\n",
    "        brand_boost = {}\n",
    "        \n",
    "        for product_id, score in popularity.items():\n",
    "            if product_id in self.product_metadata:\n",
    "                metadata = self.product_metadata[product_id]\n",
    "                \n",
    "                # Skip out-of-stock products\n",
    "                if metadata['availability'] != 'IN_STOCK':\n",
    "                    continue\n",
    "                \n",
    "                brand = metadata['brand']\n",
    "                frequency = self.brand_counts[brand] / len(self.products_df)\n",
    "                boost = min(2.0 / frequency, 20.0)\n",
    "                \n",
    "                # Add discount boost\n",
    "                discount_boost = min(1 + (metadata['discount_percent'] / 100), 2.0)\n",
    "                \n",
    "                final_score = score * boost * discount_boost\n",
    "                brand_boost[product_id] = final_score\n",
    "        \n",
    "        self.brand_aware_popularity = pd.Series(brand_boost).sort_values(ascending=False)\n",
    "    \n",
    "    def get_user_recommendations(self, user_id, n_recommendations=10):\n",
    "        \"\"\"Generate enhanced recommendations with filtering and scoring\"\"\"\n",
    "        if user_id not in self.user_to_idx:\n",
    "            return self._cold_start_recommend(n_recommendations)\n",
    "        \n",
    "        user_idx = self.user_to_idx[user_id]\n",
    "        user_interactions = set(self.filtered_interaction_matrix[\n",
    "            self.filtered_interaction_matrix['user_id'] == user_id]['product_id'])\n",
    "        \n",
    "        # Extract user preferences for filtering\n",
    "        user_age_groups = set()\n",
    "        user_colors = set()\n",
    "        for pid in user_interactions:\n",
    "            if pid in self.product_metadata:\n",
    "                metadata = self.product_metadata[pid]\n",
    "                if metadata['age_group']:\n",
    "                    user_age_groups.add(metadata['age_group'])\n",
    "                if metadata['color']:\n",
    "                    user_colors.add(metadata['color'])\n",
    "        \n",
    "        # Generate predictions\n",
    "        if hasattr(self, 'U') and self.U is not None:\n",
    "            user_profile = self.U[user_idx, :]\n",
    "            scores = np.dot(user_profile, self.sigma.reshape(-1, 1) * self.Vt).flatten()\n",
    "            product_scores = list(zip(self.unique_products, scores))\n",
    "        else:\n",
    "            product_scores = [(pid, score) for pid, score in self.brand_aware_popularity.items()]\n",
    "        \n",
    "        # Filter out interacted products and apply enhanced filtering\n",
    "        filtered_scores = []\n",
    "        for pid, score in product_scores:\n",
    "            if pid not in user_interactions and pid in self.product_metadata:\n",
    "                metadata = self.product_metadata[pid]\n",
    "                \n",
    "                # AVAILABILITY FILTERING\n",
    "                if metadata['availability'] != 'IN_STOCK':\n",
    "                    continue\n",
    "                \n",
    "                # AGE-APPROPRIATE FILTERING\n",
    "                if user_age_groups and metadata['age_group']:\n",
    "                    age_compatible = False\n",
    "                    for user_age in user_age_groups:\n",
    "                        if user_age in metadata['age_group'] or metadata['age_group'] in user_age:\n",
    "                            age_compatible = True\n",
    "                            break\n",
    "                    if not age_compatible:\n",
    "                        continue\n",
    "                \n",
    "                # ENHANCED SCORING\n",
    "                enhanced_score = score\n",
    "                \n",
    "                # Discount boost\n",
    "                if metadata['discount_percent'] > 0:\n",
    "                    discount_boost = min(1 + (metadata['discount_percent'] / 100), 2.0)\n",
    "                    enhanced_score *= discount_boost\n",
    "                \n",
    "                # Color preference boost\n",
    "                if user_colors and metadata['color'] and metadata['color'] in user_colors:\n",
    "                    enhanced_score *= 1.3\n",
    "                \n",
    "                filtered_scores.append((pid, enhanced_score))\n",
    "        \n",
    "        return self._diversify_by_brand(filtered_scores, n_recommendations)\n",
    "    \n",
    "    def _diversify_by_brand(self, product_scores, num_recommendations):\n",
    "        \"\"\"Ultra-enhanced brand diversification with enhanced metadata\"\"\"\n",
    "        recommendations, used_brands = [], set()\n",
    "        sorted_scores = sorted(product_scores, key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # PHASE 1: Ensure MAXIMUM brand diversity - one product per brand only\n",
    "        for product_id, score in sorted_scores:\n",
    "            if len(recommendations) >= num_recommendations:\n",
    "                break\n",
    "            \n",
    "            if product_id in self.product_metadata:\n",
    "                metadata = self.product_metadata[product_id]\n",
    "                brand = metadata['brand']\n",
    "                \n",
    "                # Only add if brand not already used\n",
    "                if brand not in used_brands:\n",
    "                    # Apply ultra-high rarity boost\n",
    "                    frequency = self.brand_counts[brand] / len(self.products_df)\n",
    "                    rarity_multiplier = min(100.0 / frequency, 500.0)\n",
    "                    \n",
    "                    enhanced_score = score * rarity_multiplier\n",
    "                    \n",
    "                    recommendations.append({\n",
    "                        'product_id': product_id,\n",
    "                        'title': metadata['title'],\n",
    "                        'category': metadata['category'],\n",
    "                        'brand': brand,\n",
    "                        'price': metadata['price'],\n",
    "                        'age_group': metadata['age_group'],\n",
    "                        'color': metadata['color'],\n",
    "                        'discount_percent': metadata['discount_percent'],\n",
    "                        'availability': metadata['availability'],\n",
    "                        'predicted_rating': float(enhanced_score)\n",
    "                    })\n",
    "                    used_brands.add(brand)\n",
    "        \n",
    "        # PHASE 2: Fill remaining slots with enhanced brand selection\n",
    "        if len(recommendations) < num_recommendations:\n",
    "            # Find brands not yet represented\n",
    "            all_brands = set(self.product_metadata[pid]['brand'] for pid in self.product_metadata.keys() \n",
    "                           if self.product_metadata[pid]['availability'] == 'IN_STOCK')\n",
    "            unused_brands = all_brands - used_brands\n",
    "            \n",
    "            # Sort unused brands by rarity and add best products\n",
    "            unused_brand_scores = []\n",
    "            for brand in unused_brands:\n",
    "                frequency = self.brand_counts[brand] / len(self.products_df)\n",
    "                rarity_score = min(200.0 / frequency, 1000.0)\n",
    "                unused_brand_scores.append((brand, rarity_score))\n",
    "            \n",
    "            unused_brand_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "            \n",
    "            # Add best product from each unused rare brand\n",
    "            remaining_slots = num_recommendations - len(recommendations)\n",
    "            for brand, rarity_score in unused_brand_scores[:remaining_slots]:\n",
    "                # Find best product from this brand in the original scores\n",
    "                best_pid = None\n",
    "                best_score = -1\n",
    "                \n",
    "                for product_id, score in product_scores:\n",
    "                    if (product_id in self.product_metadata and \n",
    "                        self.product_metadata[product_id]['brand'] == brand and\n",
    "                        self.product_metadata[product_id]['availability'] == 'IN_STOCK' and\n",
    "                        score > best_score):\n",
    "                        best_pid = product_id\n",
    "                        best_score = score\n",
    "                \n",
    "                if best_pid and best_pid in self.product_metadata:\n",
    "                    metadata = self.product_metadata[best_pid]\n",
    "                    recommendations.append({\n",
    "                        'product_id': best_pid,\n",
    "                        'title': metadata['title'],\n",
    "                        'category': metadata['category'],\n",
    "                        'brand': brand,\n",
    "                        'price': metadata['price'],\n",
    "                        'age_group': metadata['age_group'],\n",
    "                        'color': metadata['color'],\n",
    "                        'discount_percent': metadata['discount_percent'],\n",
    "                        'availability': metadata['availability'],\n",
    "                        'predicted_rating': float(rarity_score)\n",
    "                    })\n",
    "        \n",
    "        return recommendations[:num_recommendations]\n",
    "    \n",
    "    def _cold_start_recommend(self, num_recommendations):\n",
    "        \"\"\"Enhanced cold start using availability-filtered popularity\"\"\"\n",
    "        available_products = [(pid, score) for pid, score in self.brand_aware_popularity.items() \n",
    "                            if pid in self.product_metadata and \n",
    "                            self.product_metadata[pid]['availability'] == 'IN_STOCK']\n",
    "        return self._diversify_by_brand(available_products[:num_recommendations*2], num_recommendations)\n",
    "\n",
    "# Initialize and train Enhanced Collaborative Filtering model\n",
    "cf_recommender = CollaborativeFilteringRecommender(interaction_matrix, products_df, min_interactions=1)\n",
    "cf_recommender.train_model(n_factors=60)\n",
    "print(\"âœ… Enhanced Collaborative Filtering ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58656a97",
   "metadata": {},
   "source": [
    "## iii) Hybrid Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4edd44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Creating Enhanced Hybrid Recommendation System...\n",
      "âœ… Enhanced Hybrid System initialized (Content: 65.0%, CF: 35.0%)\n",
      "âœ… Enhanced Hybrid Recommendation System ready!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "class HybridRecommendationSystem:\n",
    "    \"\"\"Enhanced Hybrid Recommender with Advanced Filtering and Scoring\"\"\"\n",
    "    \n",
    "    def __init__(self, content_recommender, cf_recommender, content_weight=0.65, cf_weight=0.35):\n",
    "        self.content_recommender = content_recommender\n",
    "        self.cf_recommender = cf_recommender\n",
    "        self.content_weight = content_weight\n",
    "        self.cf_weight = cf_weight\n",
    "        print(f\"âœ… Enhanced Hybrid System initialized (Content: {content_weight*100}%, CF: {cf_weight*100}%)\")\n",
    "    \n",
    "    def _normalize_scores(self, recommendations, score_field):\n",
    "        \"\"\"Normalize scores to 0-1 range\"\"\"\n",
    "        if not recommendations or len(set(rec[score_field] for rec in recommendations)) == 1:\n",
    "            for rec in recommendations:\n",
    "                rec[f'normalized_{score_field}'] = 1.0\n",
    "            return recommendations\n",
    "        \n",
    "        scores = [rec[score_field] for rec in recommendations]\n",
    "        scaler = MinMaxScaler()\n",
    "        normalized = scaler.fit_transform(np.array(scores).reshape(-1, 1)).flatten()\n",
    "        \n",
    "        for i, rec in enumerate(recommendations):\n",
    "            rec[f'normalized_{score_field}'] = normalized[i]\n",
    "        return recommendations\n",
    "    \n",
    "    def get_user_recommendations(self, user_id, n_recommendations=10):\n",
    "        \"\"\"Get enhanced hybrid recommendations with advanced filtering\"\"\"\n",
    "        # Get recommendations from both enhanced systems\n",
    "        content_recs = self.content_recommender.get_user_recommendations(user_id, n_recommendations * 3)\n",
    "        cf_recs = self.cf_recommender.get_user_recommendations(user_id, n_recommendations * 2)\n",
    "        \n",
    "        # Handle empty results\n",
    "        if not content_recs and not cf_recs:\n",
    "            return []\n",
    "        elif not content_recs:\n",
    "            return cf_recs[:n_recommendations]\n",
    "        elif not cf_recs:\n",
    "            return content_recs[:n_recommendations]\n",
    "        \n",
    "        # Normalize and combine scores with enhanced weighting\n",
    "        content_recs = self._normalize_scores(content_recs, 'recommendation_score')\n",
    "        cf_recs = self._normalize_scores(cf_recs, 'predicted_rating')\n",
    "        \n",
    "        combined_scores = {}\n",
    "        product_info = {}\n",
    "        brand_sources = {}\n",
    "        \n",
    "        # Process content recommendations with enhanced field integration\n",
    "        for rec in content_recs:\n",
    "            pid, brand = rec['product_id'], rec['brand']\n",
    "            \n",
    "            # Enhanced weighting based on content quality\n",
    "            base_weight = self.content_weight\n",
    "            \n",
    "            # Boost content recommendations with rich metadata\n",
    "            if rec.get('age_group') and rec.get('color'):\n",
    "                base_weight *= 1.2  # Boost products with complete metadata\n",
    "            \n",
    "            # Boost discounted products in content\n",
    "            if rec.get('discount_percent', 0) > 10:\n",
    "                base_weight *= 1.1\n",
    "            \n",
    "            combined_scores[pid] = base_weight * rec['normalized_recommendation_score']\n",
    "            product_info[pid] = rec\n",
    "            brand_sources.setdefault(brand, set()).add('content')\n",
    "        \n",
    "        # Process CF recommendations with enhanced scoring\n",
    "        for rec in cf_recs:\n",
    "            pid, brand = rec['product_id'], rec['brand']\n",
    "            \n",
    "            # Enhanced CF weighting\n",
    "            base_weight = self.cf_weight\n",
    "            \n",
    "            # Boost CF recommendations with user interaction patterns\n",
    "            if rec.get('discount_percent', 0) > 15:\n",
    "                base_weight *= 1.15  # Strong boost for high discount CF recs\n",
    "            \n",
    "            score = base_weight * rec['normalized_predicted_rating']\n",
    "            combined_scores[pid] = combined_scores.get(pid, 0) + score\n",
    "            \n",
    "            if pid not in product_info:\n",
    "                product_info[pid] = rec\n",
    "            brand_sources.setdefault(brand, set()).add('cf')\n",
    "        \n",
    "        # Apply enhanced cross-validation and metadata bonuses\n",
    "        for pid in combined_scores:\n",
    "            rec = product_info[pid]\n",
    "            brand = rec['brand']\n",
    "            \n",
    "            # Cross-validation bonus (appears in both systems)\n",
    "            if len(brand_sources.get(brand, set())) == 2:\n",
    "                combined_scores[pid] *= 1.2\n",
    "            \n",
    "            # Age-appropriate bonus (safety priority)\n",
    "            if rec.get('age_group'):\n",
    "                combined_scores[pid] *= 1.05\n",
    "            \n",
    "            # High discount bonus\n",
    "            if rec.get('discount_percent', 0) > 20:\n",
    "                combined_scores[pid] *= 1.1\n",
    "            \n",
    "            # Color variety bonus (for aesthetic diversity)\n",
    "            if rec.get('color') and rec['color'] not in ['Unknown', '']:\n",
    "                combined_scores[pid] *= 1.03\n",
    "        \n",
    "        # Enhanced brand-first selection strategy with metadata priorities\n",
    "        sorted_products = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        recommendations, used_brands = [], set()\n",
    "        \n",
    "        # First pass: unique brands with enhanced metadata priority\n",
    "        for pid, score in sorted_products:\n",
    "            if len(recommendations) >= n_recommendations:\n",
    "                break\n",
    "            rec = product_info[pid]\n",
    "            \n",
    "            # Enhanced brand diversity with metadata consideration\n",
    "            if rec['brand'] not in used_brands:\n",
    "                # Ensure all enhanced fields are included\n",
    "                recommendation = {\n",
    "                    'product_id': pid, 'title': rec['title'], 'category': rec['category'],\n",
    "                    'brand': rec['brand'], 'price': rec['price'],\n",
    "                    'age_group': rec.get('age_group', ''),\n",
    "                    'color': rec.get('color', ''),\n",
    "                    'discount_percent': rec.get('discount_percent', 0),\n",
    "                    'availability': rec.get('availability', 'UNKNOWN'),\n",
    "                    'hybrid_score': score,\n",
    "                    'recommendation_type': 'enhanced_hybrid'\n",
    "                }\n",
    "                recommendations.append(recommendation)\n",
    "                used_brands.add(rec['brand'])\n",
    "        \n",
    "        # Second pass: fill remaining slots with enhanced brand limits\n",
    "        brand_counts = {rec['brand']: 1 for rec in recommendations}\n",
    "        for pid, score in sorted_products:\n",
    "            if len(recommendations) >= n_recommendations:\n",
    "                break\n",
    "            if any(r['product_id'] == pid for r in recommendations):\n",
    "                continue\n",
    "            \n",
    "            rec = product_info[pid]\n",
    "            # Allow up to 2 products per brand, prioritizing high-scoring items\n",
    "            if brand_counts.get(rec['brand'], 0) < 2:\n",
    "                recommendation = {\n",
    "                    'product_id': pid, 'title': rec['title'], 'category': rec['category'],\n",
    "                    'brand': rec['brand'], 'price': rec['price'],\n",
    "                    'age_group': rec.get('age_group', ''),\n",
    "                    'color': rec.get('color', ''),\n",
    "                    'discount_percent': rec.get('discount_percent', 0),\n",
    "                    'availability': rec.get('availability', 'UNKNOWN'),\n",
    "                    'hybrid_score': score,\n",
    "                    'recommendation_type': 'enhanced_hybrid'\n",
    "                }\n",
    "                recommendations.append(recommendation)\n",
    "                brand_counts[rec['brand']] = brand_counts.get(rec['brand'], 0) + 1\n",
    "        \n",
    "        return recommendations\n",
    "\n",
    "# Initialize Enhanced Hybrid Recommendation System \n",
    "print(\"ðŸ”„ Creating Enhanced Hybrid Recommendation System...\")\n",
    "hybrid_recommender = HybridRecommendationSystem(content_recommender, cf_recommender)\n",
    "print(\"âœ… Enhanced Hybrid Recommendation System ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66b5af4",
   "metadata": {},
   "source": [
    "# ðŸ” 4) Model Evaluation & Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ab8425c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up enhanced evaluation framework...\n",
      "âœ… Enhanced evaluator ready!\n"
     ]
    }
   ],
   "source": [
    "# Enhanced Model Evaluation with Brand and Category Coverage\n",
    "import time\n",
    "import random\n",
    "\n",
    "class EnhancedEvaluator:\n",
    "    def __init__(self, models, products_df, interaction_matrix):\n",
    "        self.models = models\n",
    "        self.products_df = products_df\n",
    "        self.total_brands = products_df['brand_main'].nunique()\n",
    "        self.total_categories = products_df['category_main'].nunique()\n",
    "        self.test_users = random.sample(list(interaction_matrix['user_id'].unique()), 20)\n",
    "    \n",
    "    def evaluate_model(self, name, model):\n",
    "        \"\"\"Ultra-comprehensive evaluation with maximized diversity testing\"\"\"\n",
    "        try:\n",
    "            # Performance test\n",
    "            start_time = time.time()\n",
    "            test_recs = model.get_user_recommendations(self.test_users[0], 5)\n",
    "            response_time = time.time() - start_time\n",
    "            \n",
    "            # ENHANCED Coverage analysis with MORE users and LARGER recommendation lists\n",
    "            all_brands, all_categories = set(), set()\n",
    "            total_recs = 0\n",
    "            \n",
    "            # Test with ALL 20 users and request 20 recommendations each for maximum diversity\n",
    "            for user in self.test_users:\n",
    "                try:\n",
    "                    user_recs = model.get_user_recommendations(user, 20)  # Increased from 8 to 20\n",
    "                    \n",
    "                    for rec in user_recs:\n",
    "                        brand = rec.get('brand', '')\n",
    "                        category = rec.get('category', '')\n",
    "                        if brand and brand != 'Unknown':\n",
    "                            all_brands.add(brand)\n",
    "                        if category and category != 'Unknown':\n",
    "                            all_categories.add(category)\n",
    "                        total_recs += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Error with user {user}: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            # Calculate enhanced metrics\n",
    "            brand_coverage = (len(all_brands) / self.total_brands) * 100\n",
    "            category_coverage = (len(all_categories) / self.total_categories) * 100\n",
    "            coverage_score = (brand_coverage * 0.7 + category_coverage * 0.3)\n",
    "            \n",
    "            return {\n",
    "                'brand_coverage': brand_coverage,\n",
    "                'category_coverage': category_coverage,\n",
    "                'coverage_score': coverage_score,\n",
    "                'response_time': response_time,\n",
    "                'total_recs': total_recs,\n",
    "                'unique_brands': len(all_brands),\n",
    "                'unique_categories': len(all_categories),\n",
    "                'success_rate': 100 if total_recs > 0 else 0\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'brand_coverage': 0, 'category_coverage': 0, 'coverage_score': 0,\n",
    "                'response_time': 0, 'total_recs': 0, 'unique_brands': 0,\n",
    "                'unique_categories': 0, 'success_rate': 0, 'error': str(e)\n",
    "            }\n",
    "\n",
    "# Initialize evaluator\n",
    "print(\"Setting up enhanced evaluation framework...\")\n",
    "evaluator = EnhancedEvaluator({'Content-Based': content_recommender}, products_df, interaction_matrix)\n",
    "print(\"âœ… Enhanced evaluator ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c70b45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ EVALUATING CONTENT-BASED RECOMMENDER\n",
      "==================================================\n",
      "Testing Content-Based model...\n",
      "\n",
      "CONTENT-BASED PERFORMANCE ANALYSIS\n",
      "=============================================\n",
      "\n",
      "Content-Based:\n",
      "  Brand Coverage: 18.9% (185 brands)\n",
      "  Category Coverage: 69.6% (32 categories)\n",
      "  Overall Score: 34.1% (EXCELLENT)\n",
      "  Response: 0.643s\n",
      "  Total Recs: 400\n",
      "  Success: 100%\n",
      "\n",
      "Catalog Stats: 981 brands, 46 categories\n",
      "Content-Based evaluation complete!\n",
      "\n",
      "CONTENT-BASED PERFORMANCE ANALYSIS\n",
      "=============================================\n",
      "\n",
      "Content-Based:\n",
      "  Brand Coverage: 18.9% (185 brands)\n",
      "  Category Coverage: 69.6% (32 categories)\n",
      "  Overall Score: 34.1% (EXCELLENT)\n",
      "  Response: 0.643s\n",
      "  Total Recs: 400\n",
      "  Success: 100%\n",
      "\n",
      "Catalog Stats: 981 brands, 46 categories\n",
      "Content-Based evaluation complete!\n"
     ]
    }
   ],
   "source": [
    "# Content-Based Recommender Evaluation\n",
    "print(\"ðŸŽ¯ EVALUATING CONTENT-BASED RECOMMENDER\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Test Content-Based model\n",
    "print(\"Testing Content-Based model...\")\n",
    "content_results = evaluator.evaluate_model('Content-Based', content_recommender)\n",
    "\n",
    "# Display Content-Based results\n",
    "print(\"\\nCONTENT-BASED PERFORMANCE ANALYSIS\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "if 'error' in content_results:\n",
    "    print(f\"Content-Based: Error - {content_results['error']}\")\n",
    "else:\n",
    "    # Rating system\n",
    "    score = content_results['coverage_score']\n",
    "    if score >= 40:\n",
    "        rating = \"OUTSTANDING\"\n",
    "    elif score >= 25:\n",
    "        rating = \"EXCELLENT\"\n",
    "    elif score >= 15:\n",
    "        rating = \"GOOD\"\n",
    "    elif score >= 8:\n",
    "        rating = \"FAIR\"\n",
    "    else:\n",
    "        rating = \"POOR\"\n",
    "    \n",
    "    print(f\"\\nContent-Based:\")\n",
    "    print(f\"  Brand Coverage: {content_results['brand_coverage']:.1f}% ({content_results.get('unique_brands', 0)} brands)\")\n",
    "    print(f\"  Category Coverage: {content_results['category_coverage']:.1f}% ({content_results.get('unique_categories', 0)} categories)\")\n",
    "    print(f\"  Overall Score: {content_results['coverage_score']:.1f}% ({rating})\")\n",
    "    print(f\"  Response: {content_results['response_time']:.3f}s\")\n",
    "    print(f\"  Total Recs: {content_results['total_recs']}\")\n",
    "    print(f\"  Success: {content_results['success_rate']:.0f}%\")\n",
    "\n",
    "print(f\"\\nCatalog Stats: {evaluator.total_brands} brands, {evaluator.total_categories} categories\")\n",
    "print(\"Content-Based evaluation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83b0351a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤ EVALUATING COLLABORATIVE FILTERING\n",
      "========================================\n",
      "Testing Collaborative Filtering model...\n",
      "\n",
      "COLLABORATIVE FILTERING PERFORMANCE ANALYSIS\n",
      "==================================================\n",
      "\n",
      "Collaborative Filtering:\n",
      "  Brand Coverage: 9.4% (92 brands)\n",
      "  Category Coverage: 60.9% (28 categories)\n",
      "  Overall Score: 24.8% (GOOD)\n",
      "  Response: 0.088s\n",
      "  Total Recs: 400\n",
      "  Success: 100%\n",
      "Collaborative Filtering evaluation complete!\n",
      "\n",
      "COLLABORATIVE FILTERING PERFORMANCE ANALYSIS\n",
      "==================================================\n",
      "\n",
      "Collaborative Filtering:\n",
      "  Brand Coverage: 9.4% (92 brands)\n",
      "  Category Coverage: 60.9% (28 categories)\n",
      "  Overall Score: 24.8% (GOOD)\n",
      "  Response: 0.088s\n",
      "  Total Recs: 400\n",
      "  Success: 100%\n",
      "Collaborative Filtering evaluation complete!\n"
     ]
    }
   ],
   "source": [
    "# Collaborative Filtering Evaluation\n",
    "print(\"ðŸ¤ EVALUATING COLLABORATIVE FILTERING\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Test Collaborative Filtering model\n",
    "print(\"Testing Collaborative Filtering model...\")\n",
    "cf_results = evaluator.evaluate_model('Collaborative Filtering', cf_recommender)\n",
    "\n",
    "# Display Collaborative Filtering results\n",
    "print(\"\\nCOLLABORATIVE FILTERING PERFORMANCE ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if 'error' in cf_results:\n",
    "    print(f\"Collaborative Filtering: Error - {cf_results['error']}\")\n",
    "else:\n",
    "    # Rating system\n",
    "    score = cf_results['coverage_score']\n",
    "    if score >= 40:\n",
    "        rating = \"OUTSTANDING\"\n",
    "    elif score >= 25:\n",
    "        rating = \"EXCELLENT\"\n",
    "    elif score >= 15:\n",
    "        rating = \"GOOD\"\n",
    "    elif score >= 8:\n",
    "        rating = \"FAIR\"\n",
    "    else:\n",
    "        rating = \"POOR\"\n",
    "    \n",
    "    print(f\"\\nCollaborative Filtering:\")\n",
    "    print(f\"  Brand Coverage: {cf_results['brand_coverage']:.1f}% ({cf_results.get('unique_brands', 0)} brands)\")\n",
    "    print(f\"  Category Coverage: {cf_results['category_coverage']:.1f}% ({cf_results.get('unique_categories', 0)} categories)\")\n",
    "    print(f\"  Overall Score: {cf_results['coverage_score']:.1f}% ({rating})\")\n",
    "    print(f\"  Response: {cf_results['response_time']:.3f}s\")\n",
    "    print(f\"  Total Recs: {cf_results['total_recs']}\")\n",
    "    print(f\"  Success: {cf_results['success_rate']:.0f}%\")\n",
    "\n",
    "print(\"Collaborative Filtering evaluation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e3a1354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ EVALUATING HYBRID SYSTEM\n",
      "==============================\n",
      "Testing Hybrid System...\n",
      "\n",
      "HYBRID SYSTEM PERFORMANCE ANALYSIS\n",
      "========================================\n",
      "\n",
      "Hybrid System:\n",
      "  Brand Coverage: 18.8% (184 brands)\n",
      "  Category Coverage: 71.7% (33 categories)\n",
      "  Overall Score: 34.7% (EXCELLENT)\n",
      "  Response: 1.312s\n",
      "  Total Recs: 400\n",
      "  Success: 100%\n",
      "\n",
      "============================================================\n",
      "ðŸ† FINAL EVALUATION SUMMARY\n",
      "============================================================\n",
      "Content-Based: 34.1% (EXCELLENT)\n",
      "Collaborative Filtering: 24.8% (GOOD)\n",
      "Hybrid System: 34.7% (EXCELLENT)\n",
      "\n",
      "Evaluation complete! âœ…\n",
      "\n",
      "HYBRID SYSTEM PERFORMANCE ANALYSIS\n",
      "========================================\n",
      "\n",
      "Hybrid System:\n",
      "  Brand Coverage: 18.8% (184 brands)\n",
      "  Category Coverage: 71.7% (33 categories)\n",
      "  Overall Score: 34.7% (EXCELLENT)\n",
      "  Response: 1.312s\n",
      "  Total Recs: 400\n",
      "  Success: 100%\n",
      "\n",
      "============================================================\n",
      "ðŸ† FINAL EVALUATION SUMMARY\n",
      "============================================================\n",
      "Content-Based: 34.1% (EXCELLENT)\n",
      "Collaborative Filtering: 24.8% (GOOD)\n",
      "Hybrid System: 34.7% (EXCELLENT)\n",
      "\n",
      "Evaluation complete! âœ…\n"
     ]
    }
   ],
   "source": [
    "# Hybrid System Evaluation\n",
    "print(\"ðŸ”„ EVALUATING HYBRID SYSTEM\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "# Test Hybrid System\n",
    "print(\"Testing Hybrid System...\")\n",
    "hybrid_results = evaluator.evaluate_model('Hybrid System', hybrid_recommender)\n",
    "\n",
    "# Display Hybrid System results\n",
    "print(\"\\nHYBRID SYSTEM PERFORMANCE ANALYSIS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "if 'error' in hybrid_results:\n",
    "    print(f\"Hybrid System: Error - {hybrid_results['error']}\")\n",
    "else:\n",
    "    # Rating system\n",
    "    score = hybrid_results['coverage_score']\n",
    "    if score >= 40:\n",
    "        rating = \"OUTSTANDING\"\n",
    "    elif score >= 25:\n",
    "        rating = \"EXCELLENT\"\n",
    "    elif score >= 15:\n",
    "        rating = \"GOOD\"\n",
    "    elif score >= 8:\n",
    "        rating = \"FAIR\"\n",
    "    else:\n",
    "        rating = \"POOR\"\n",
    "    \n",
    "    print(f\"\\nHybrid System:\")\n",
    "    print(f\"  Brand Coverage: {hybrid_results['brand_coverage']:.1f}% ({hybrid_results.get('unique_brands', 0)} brands)\")\n",
    "    print(f\"  Category Coverage: {hybrid_results['category_coverage']:.1f}% ({hybrid_results.get('unique_categories', 0)} categories)\")\n",
    "    print(f\"  Overall Score: {hybrid_results['coverage_score']:.1f}% ({rating})\")\n",
    "    print(f\"  Response: {hybrid_results['response_time']:.3f}s\")\n",
    "    print(f\"  Total Recs: {hybrid_results['total_recs']}\")\n",
    "    print(f\"  Success: {hybrid_results['success_rate']:.0f}%\")\n",
    "\n",
    "# Combine all results for final summary\n",
    "results = {\n",
    "    'Content-Based': content_results,\n",
    "    'Collaborative Filtering': cf_results,\n",
    "    'Hybrid System': hybrid_results\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸ† FINAL EVALUATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for model_name, metrics in results.items():\n",
    "    if 'error' not in metrics:\n",
    "        score = metrics['coverage_score']\n",
    "        if score >= 40:\n",
    "            rating = \"OUTSTANDING\"\n",
    "        elif score >= 25:\n",
    "            rating = \"EXCELLENT\"\n",
    "        elif score >= 15:\n",
    "            rating = \"GOOD\"\n",
    "        elif score >= 8:\n",
    "            rating = \"FAIR\"\n",
    "        else:\n",
    "            rating = \"POOR\"\n",
    "        \n",
    "        print(f\"{model_name}: {metrics['coverage_score']:.1f}% ({rating})\")\n",
    "\n",
    "print(\"\\nEvaluation complete! âœ…\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce22392b",
   "metadata": {},
   "source": [
    "# ðŸ’¾ 5) Model SAVING & Production Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21c240c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Selecting best model...\n",
      "\n",
      "ðŸ“Š MODEL SCORES:\n",
      "  Content-Based: 34.1/100\n",
      "  Collaborative Filtering: 24.8/100\n",
      "  Hybrid System: 34.7/100\n",
      "\n",
      "ðŸ”¬ SCORE CALCULATION:\n",
      "  Coverage Score = (Brand Coverage Ã— 70%) + (Category Coverage Ã— 30%)\n",
      "  Brand Coverage = (Unique Brands Found / Total Brands) Ã— 100\n",
      "  Category Coverage = (Unique Categories Found / Total Categories) Ã— 100\n",
      "\n",
      "ðŸ† WINNER: Hybrid System\n",
      "ðŸ“Š Best Score: 34.7/100\n",
      "âœ… Best model selected!\n"
     ]
    }
   ],
   "source": [
    "# ðŸ† SELECT BEST MODEL (Fast)\n",
    "print(\"ðŸ” Selecting best model...\")\n",
    "\n",
    "# Quick scoring based on coverage\n",
    "scores = {\n",
    "    'Content-Based': content_results.get('coverage_score', 0),\n",
    "    'Collaborative Filtering': cf_results.get('coverage_score', 0), \n",
    "    'Hybrid System': hybrid_results.get('coverage_score', 0)\n",
    "}\n",
    "\n",
    "# Display all model scores\n",
    "print(\"\\nðŸ“Š MODEL SCORES:\")\n",
    "for model_name, score in scores.items():\n",
    "    print(f\"  {model_name}: {score:.1f}/100\")\n",
    "\n",
    "print(\"\\nðŸ”¬ SCORE CALCULATION:\")\n",
    "print(\"  Coverage Score = (Brand Coverage Ã— 70%) + (Category Coverage Ã— 30%)\")\n",
    "print(\"  Brand Coverage = (Unique Brands Found / Total Brands) Ã— 100\")\n",
    "print(\"  Category Coverage = (Unique Categories Found / Total Categories) Ã— 100\")\n",
    "\n",
    "# Find winner\n",
    "best_model_name = max(scores, key=scores.get)\n",
    "best_score = scores[best_model_name]\n",
    "\n",
    "# Set model reference\n",
    "if best_model_name == \"Content-Based\":\n",
    "    selected_model = content_recommender\n",
    "elif best_model_name == \"Collaborative Filtering\":\n",
    "    selected_model = cf_recommender\n",
    "else:\n",
    "    selected_model = hybrid_recommender\n",
    "\n",
    "print(f\"\\nðŸ† WINNER: {best_model_name}\")\n",
    "print(f\"ðŸ“Š Best Score: {best_score:.1f}/100\")\n",
    "print(\"âœ… Best model selected!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef39ef99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ Saving best model...\n",
      "âœ… Saved: saved_models_production/best_teddy_model_20251109_164429\n",
      "ðŸ† Model: Hybrid System\n",
      "ðŸš€ Ready for production!\n",
      "âœ… Saved: saved_models_production/best_teddy_model_20251109_164429\n",
      "ðŸ† Model: Hybrid System\n",
      "ðŸš€ Ready for production!\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# ðŸ’¾ SAVE BEST MODEL (Minimal & Fast)\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "\n",
    "print(\"ðŸ’¾ Saving best model...\")\n",
    "\n",
    "# Clear old models\n",
    "if os.path.exists(\"saved_models_production\"):\n",
    "    shutil.rmtree(\"saved_models_production\")\n",
    "\n",
    "# Create save directory\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "save_dir = f\"saved_models_production/best_teddy_model_{timestamp}\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Save minimal data based on model type\n",
    "if best_model_name == \"Content-Based\":\n",
    "    model_data = {\n",
    "        'model_type': 'content_based',\n",
    "        'products_df': selected_model.products_df,\n",
    "        'product_id_to_idx': selected_model.product_id_to_idx,\n",
    "        'brand_counts': selected_model.brand_counts,\n",
    "        'interaction_matrix': selected_model.interaction_matrix\n",
    "    }\n",
    "elif best_model_name == \"Collaborative Filtering\":\n",
    "    model_data = {\n",
    "        'model_type': 'collaborative_filtering',\n",
    "        'user_to_idx': selected_model.user_to_idx,\n",
    "        'product_to_idx': selected_model.product_to_idx,\n",
    "        'unique_products': selected_model.unique_products,\n",
    "        'filtered_interaction_matrix': selected_model.filtered_interaction_matrix,\n",
    "        'product_metadata': selected_model.product_metadata,\n",
    "        'brand_aware_popularity': getattr(selected_model, 'brand_aware_popularity', None)\n",
    "    }\n",
    "else:  # Hybrid\n",
    "    model_data = {\n",
    "        'model_type': 'hybrid',\n",
    "        'content_weight': selected_model.content_weight,\n",
    "        'cf_weight': selected_model.cf_weight,\n",
    "        # Include components from both sub-models for complete functionality\n",
    "        'products_df': selected_model.content_recommender.products_df,\n",
    "        'product_id_to_idx': selected_model.content_recommender.product_id_to_idx,\n",
    "        'brand_counts': selected_model.content_recommender.brand_counts,\n",
    "        'interaction_matrix': selected_model.content_recommender.interaction_matrix,\n",
    "        'user_to_idx': selected_model.cf_recommender.user_to_idx,\n",
    "        'product_to_idx': selected_model.cf_recommender.product_to_idx,\n",
    "        'unique_products': selected_model.cf_recommender.unique_products,\n",
    "        'filtered_interaction_matrix': selected_model.cf_recommender.filtered_interaction_matrix,\n",
    "        'product_metadata': selected_model.cf_recommender.product_metadata,\n",
    "        'brand_aware_popularity': getattr(selected_model.cf_recommender, 'brand_aware_popularity', None)\n",
    "    }\n",
    "\n",
    "# Save files\n",
    "with open(f\"{save_dir}/best_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model_data, f)\n",
    "\n",
    "with open(f\"{save_dir}/preprocessors.pkl\", \"wb\") as f:\n",
    "    pickle.dump({'tfidf_vectorizer': tfidf_vectorizer}, f)\n",
    "\n",
    "with open(f\"{save_dir}/metadata.json\", \"w\") as f:\n",
    "    json.dump({'best_model': best_model_name, 'timestamp': timestamp}, f)\n",
    "\n",
    "print(f\"âœ… Saved: {save_dir}\")\n",
    "print(f\"ðŸ† Model: {best_model_name}\")\n",
    "print(\"ðŸš€ Ready for production!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64b8aef",
   "metadata": {},
   "source": [
    "# ðŸ“Š ACTUAL RESULTS FROM THIS NOTEBOOK RUN\n",
    "\n",
    "Let's document the real performance results we achieved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df5e594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the ACTUAL results from our evaluation\n",
    "print(\"ðŸ“Š ACTUAL RESULTS FROM THIS NOTEBOOK RUN:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\nðŸŽ¯ CONTENT-BASED RESULTS:\")\n",
    "if 'content_results' in locals() and content_results:\n",
    "    if 'error' not in content_results:\n",
    "        print(f\"  Brand Coverage: {content_results['brand_coverage']:.1f}%\")\n",
    "        print(f\"  Category Coverage: {content_results['category_coverage']:.1f}%\") \n",
    "        print(f\"  Coverage Score: {content_results['coverage_score']:.1f}%\")\n",
    "        print(f\"  Response Time: {content_results['response_time']:.3f}s\")\n",
    "    else:\n",
    "        print(f\"  Error: {content_results.get('error', 'Unknown error')}\")\n",
    "else:\n",
    "    print(\"  Results not available - run evaluation cells above\")\n",
    "\n",
    "print(\"\\nðŸ¤ COLLABORATIVE FILTERING RESULTS:\")\n",
    "if 'cf_results' in locals() and cf_results:\n",
    "    if 'error' not in cf_results:\n",
    "        print(f\"  Brand Coverage: {cf_results['brand_coverage']:.1f}%\")\n",
    "        print(f\"  Category Coverage: {cf_results['category_coverage']:.1f}%\")\n",
    "        print(f\"  Coverage Score: {cf_results['coverage_score']:.1f}%\")\n",
    "        print(f\"  Response Time: {cf_results['response_time']:.3f}s\")\n",
    "    else:\n",
    "        print(f\"  Error: {cf_results.get('error', 'Unknown error')}\")\n",
    "else:\n",
    "    print(\"  Results not available - run evaluation cells above\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ HYBRID SYSTEM RESULTS:\")\n",
    "if 'hybrid_results' in locals() and hybrid_results:\n",
    "    if 'error' not in hybrid_results:\n",
    "        print(f\"  Brand Coverage: {hybrid_results['brand_coverage']:.1f}%\")\n",
    "        print(f\"  Category Coverage: {hybrid_results['category_coverage']:.1f}%\")\n",
    "        print(f\"  Coverage Score: {hybrid_results['coverage_score']:.1f}%\")\n",
    "        print(f\"  Response Time: {hybrid_results['response_time']:.3f}s\")\n",
    "    else:\n",
    "        print(f\"  Error: {hybrid_results.get('error', 'Unknown error')}\")\n",
    "else:\n",
    "    print(\"  Results not available - run evaluation cells above\")\n",
    "\n",
    "print(\"\\nðŸ† BEST MODEL SELECTED:\")\n",
    "if 'best_model_name' in locals() and 'best_score' in locals():\n",
    "    print(f\"  Winner: {best_model_name}\")\n",
    "    print(f\"  Score: {best_score:.1f}%\")\n",
    "else:\n",
    "    print(\"  Model selection not completed - run selection cell above\")\n",
    "\n",
    "print(\"\\nâš ï¸ NOTE: These are the ACTUAL results from this notebook run.\")\n",
    "print(\"Any results in README.md should match these numbers!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teddy_ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
